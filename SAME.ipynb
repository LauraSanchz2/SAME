{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAME.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mP4MYRlc1TW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vswIOHVeGJ2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pbO5PTVGKyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /gdrive/My Drive/fakenews_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH8_FZbuGMCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHY_Fp0HGNVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import re\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "MAX_SENT_LENGTH = 500\n",
        "MAX_NB_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.25\n",
        "\n",
        "data_train_fake = pd.read_csv('politifact_fake.csv')\n",
        "data_train_real = pd.read_csv('politifact_real.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNeGv8YiGY2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "from nltk import tokenize\n",
        "\n",
        "import cv2\n",
        "\n",
        "texts = []\n",
        "metas = []\n",
        "img_data = []\n",
        "replies = []\n",
        "\n",
        "for idx in range(data_train_fake.text.shape[0]):\n",
        "    try:\n",
        "      img_data.append(cv2.resize(cv2.imread(str(data_train_fake.id[idx])+'.jpg', cv2.IMREAD_COLOR), (224, 224), interpolation=cv2.INTER_CUBIC))\n",
        "    except:\n",
        "      # print(\"Error!\")\n",
        "      continue\n",
        "    texts.append(str(data_train_fake.text[idx]))\n",
        "    metas.append(set(str(data_train_fake.meta_data[idx]).split(' ')))\n",
        "    # replies.append(str(data_train_fake.replies[idx]))\n",
        "\n",
        "train_size = len(texts)\n",
        "labels = list(np.ones(train_size, dtype=int))\n",
        "\n",
        "for idx in range(data_train_real.text.shape[0]):\n",
        "    try:\n",
        "      img_data.append(cv2.resize(cv2.imread(str(data_train_real.id[idx])+'.jpg', cv2.IMREAD_COLOR), (224, 224), interpolation=cv2.INTER_CUBIC).tolist())\n",
        "    except:\n",
        "      # print(\"Error!\")\n",
        "      continue\n",
        "    texts.append(str(data_train_real.text[idx]))\n",
        "    metas.append(set(str(data_train_real.meta_data[idx]).split(' ')))\n",
        "    # replies.append(str(data_train_real.replies[idx]))\n",
        "\n",
        "labels += list(np.zeros(len(texts)-train_size, dtype=int))\n",
        "\n",
        "# print(labels)\n",
        "\n",
        "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "data = np.zeros((len(texts), MAX_SENT_LENGTH), dtype='int32')\n",
        "\n",
        "one_hot = MultiLabelBinarizer()\n",
        "metas = one_hot.fit_transform(metas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_MEV3i7JSVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, text in enumerate(texts):\n",
        "  wordTokens = text_to_word_sequence(text)\n",
        "  k = 0\n",
        "  for _, word in enumerate(wordTokens):\n",
        "    if k < MAX_SENT_LENGTH and tokenizer.word_index[word] < MAX_NB_WORDS:\n",
        "      data[i, k] = tokenizer.word_index[word]\n",
        "      k = k + 1\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Total %s unique tokens.' % len(word_index))\n",
        "\n",
        "labels = to_categorical(np.asarray(labels))\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "metas = metas[indices]\n",
        "img_data = np.array(img_data)[indices]\n",
        "labels = labels[indices]\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples]\n",
        "x_meta_train = metas[:-nb_validation_samples]\n",
        "x_img_train = img_data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_val = data[-nb_validation_samples:]\n",
        "x_meta_val = metas[-nb_validation_samples:]\n",
        "x_img_val = img_data[-nb_validation_samples:]\n",
        "y_val = labels[-nb_validation_samples:]\n",
        "\n",
        "print('Number of positive and negative reviews in traing and validation set')\n",
        "print(y_train.sum(axis=0))\n",
        "print(y_val.sum(axis=0))\n",
        "\n",
        "GLOVE_DIR = \".\"\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Total %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# print(data[0:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDao-UbCbrLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Embedding, LSTM, Dense, Concatenate, LeakyReLU, Dropout\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from numpy.random import randint\n",
        "# from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "def get_generative(input_tensor, main_input, auxiliary_input):\n",
        "  # Input tensor: the cover image\n",
        "  base_model = VGG16(include_top=True, weights='imagenet', input_tensor=input_tensor, input_shape=None, pooling=None, classes=1000)\n",
        "  im = base_model.output\n",
        "  # print(im.shape)\n",
        "  dense1_1 = Dense(EMBEDDING_DIM, activation='relu', name='img_output')\n",
        "  im = dense1_1(im)\n",
        "\n",
        "  embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SENT_LENGTH,\n",
        "                            trainable=True)\n",
        "  \n",
        "  # Main input: the news content\n",
        "  embedded_sequences = embedding_layer(main_input)\n",
        "  lstm_layer = LSTM(EMBEDDING_DIM, name='text_output')\n",
        "  x = lstm_layer(embedded_sequences) # MLP, LSTM, BiGRU here\n",
        "\n",
        "  # Auxiliary input: the news profile/meta data\n",
        "  dense2_1 = Dense(EMBEDDING_DIM, activation='relu')\n",
        "  me = dense2_1(auxiliary_input)\n",
        "  dense2_2 = Dense(EMBEDDING_DIM, activation='relu', name='meta_output')\n",
        "  me = dense2_2(me)\n",
        "\n",
        "  out = Concatenate(axis=1)([x, me, im])\n",
        "\n",
        "  # We stack a deep densely-connected network on top\n",
        "  out = Dense(EMBEDDING_DIM, activation='relu')(out)\n",
        "\n",
        "  # And finally we add the output layer\n",
        "  main_output = Dense(2, activation='sigmoid', name='main_output')(out)\n",
        "\n",
        "  G = Model(inputs=[input_tensor, main_input, auxiliary_input], outputs=[main_output, x], name=\"generator\")\n",
        "  G.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "  return G, main_output\n",
        "\n",
        "def get_discriminative(D_in, drate = .2, leak=.2):\n",
        "  x = Dense(EMBEDDING_DIM)(D_in)\n",
        "  x = LeakyReLU(leak)(x)\n",
        "  x = Dropout(drate)(x)\n",
        "\n",
        "  x = Dense(EMBEDDING_DIM)(x)\n",
        "  x = LeakyReLU(leak)(x)\n",
        "  D_out = Dense(3, activation='sigmoid', name='discriminator_output')(x)\n",
        "\n",
        "  D = Model(inputs=D_in, outputs=D_out, name=\"discriminator\")\n",
        "  D.compile(optimizer='rmsprop',\n",
        "            loss='mean_squared_error',\n",
        "            metrics=['acc'])\n",
        "  return D, D_out\n",
        "\n",
        "def set_trainability(model, trainable=False):\n",
        "  model.trainable = trainable\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = trainable\n",
        "\n",
        "def make_gan(GAN_input_tensor, GAN_main_input, GAN_auxiliary_input, G, D):\n",
        "  set_trainability(D, False)\n",
        "  G_output, x = G([GAN_input_tensor, GAN_main_input, GAN_auxiliary_input])\n",
        "  # im = G.get_layer('img_output').output\n",
        "  # x = G.get_layer('text_output').output\n",
        "  # me = G.get_layer('meta_output').output\n",
        "\n",
        "  GAN_out = D(x)\n",
        "\n",
        "  losses = {\n",
        "      \"generator\": \"categorical_crossentropy\",\n",
        "      \"discriminator\": \"mean_squared_error\"\n",
        "      }\n",
        "  lossWeights = {\"generator\": 1.0, \"discriminator\": 0.1}\n",
        "  GAN = Model(inputs=[GAN_input_tensor, GAN_main_input, GAN_auxiliary_input], outputs=[GAN_out, G_output])\n",
        "  GAN.compile(loss=losses, loss_weights=lossWeights, optimizer='rmsprop')\n",
        "  return GAN, GAN_out\n",
        "\n",
        "def pretrain(G, D, x_img_train, x_train, x_meta_train, batch_size=32):\n",
        "  print(\"Pretraining...\")\n",
        "  print(\"Getting results from G...\")\n",
        "  \n",
        "  L = batch_size//3\n",
        "  img_indices= np.random.randint(L*3, size=L)\n",
        "  text_indices= np.random.randint(L*3, size=L)\n",
        "  meta_indices= np.random.randint(L*3, size=L)\n",
        "  x_img_train, x_train, x_meta_train = x_img_train[img_indices], x_train[text_indices], x_meta_train[meta_indices]\n",
        "\n",
        "  img_layer_model = Model(inputs=G.inputs, outputs=G.get_layer('img_output').output)\n",
        "  text_layer_model = Model(inputs=G.inputs, outputs=G.get_layer('text_output').output)\n",
        "  meta_layer_model = Model(inputs=G.inputs, outputs=G.get_layer('meta_output').output)\n",
        "  img_output = img_layer_model.predict([x_img_train, x_train, x_meta_train])\n",
        "  text_output = text_layer_model.predict([x_img_train, x_train, x_meta_train])\n",
        "  meta_output = meta_layer_model.predict([x_img_train, x_train, x_meta_train])\n",
        "\n",
        "  X = tensorflow.concat([img_output, text_output, meta_output], 0)\n",
        "  y = np.zeros((L*3, 3))\n",
        "  y[:L, 0] = 1\n",
        "  y[L:2*L, 1] = 1\n",
        "  y[2*L:, 2] = 1\n",
        "\n",
        "  set_trainability(D, True)\n",
        "  print(\"Getting results from D...\")\n",
        "  D.fit(X, y, steps_per_epoch=batch_size)\n",
        "\n",
        "def train(GAN, G, D, dataset, y_train, epochs=10, batch_size=32, verbose=True, v_freq=1):\n",
        "  print(\"Training...\")\n",
        "  x_img_train, x_train, x_meta_train = dataset\n",
        "  # print(x_img_train.shape)\n",
        "  d_loss = []\n",
        "  g_loss = []\n",
        "  e_range = range(epochs)\n",
        "  # if verbose:\n",
        "  #   e_range = tqdm(e_range)\n",
        "    \n",
        "  for epoch in e_range:\n",
        "    img_layer_model = Model(inputs=G.inputs, outputs=G.get_layer('img_output').output)\n",
        "    text_layer_model = Model(inputs=G.inputs, outputs=G.get_layer('text_output').output)\n",
        "    meta_layer_model = Model(inputs=G.inputs, outputs=G.get_layer('meta_output').output)\n",
        "    img_output = img_layer_model.predict([x_img_train, x_train, x_meta_train])\n",
        "    text_output = text_layer_model.predict([x_img_train, x_train, x_meta_train])\n",
        "    meta_output = meta_layer_model.predict([x_img_train, x_train, x_meta_train])\n",
        "\n",
        "    L = img_output.shape[0]\n",
        "    img_indices= np.random.randint(L, size=L//3)\n",
        "    text_indices= np.random.randint(L, size=L//3)\n",
        "    meta_indices= np.random.randint(L, size=L-2*(L//3))\n",
        "    X = tensorflow.concat([img_output[img_indices], text_output[text_indices], meta_output[meta_indices]], 0)\n",
        "    y = np.zeros((L, 3))\n",
        "    y[:L//3, 0] = 1 #image\n",
        "    y[L//3:2*(L//3), 1] = 1 #text\n",
        "    y[2*(L//3):, 2] = 1 #meta data\n",
        "\n",
        "    print(\"Training D...\")\n",
        "    set_trainability(D, True)\n",
        "    d_loss.append(D.train_on_batch(X, y))\n",
        "    \n",
        "    print(\"Training GAN...\")\n",
        "    set_trainability(D, False)\n",
        "\n",
        "    y = np.zeros((L, 3))\n",
        "    y[:, 0] = 1 #fool D that all texts are images\n",
        "    g_loss.append(GAN.train_on_batch([x_img_train, x_train, x_meta_train], [y, y_train]))\n",
        "\n",
        "    y[:, 2] = 1 #fool D that all texts data are meta data\n",
        "    g_loss.append(GAN.train_on_batch([x_img_train, x_train, x_meta_train], [y, y_train]))\n",
        "        \n",
        "    if verbose and (epoch + 1) % v_freq == 0:\n",
        "      print(\"Epoch #{}: Generative Loss: {}, Discriminative Loss: {}\".format(epoch + 1, g_loss[-1], d_loss[-1]))\n",
        "        \n",
        "  return d_loss, g_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IntdSE5fHIux",
        "colab": {}
      },
      "source": [
        "G_input_tensor = Input(shape=[224, 224, 3])\n",
        "G_main_input = Input(shape=[MAX_SENT_LENGTH])\n",
        "G_auxiliary_input = Input(shape=[metas.shape[1]])\n",
        "G, G_out = get_generative(G_input_tensor, G_main_input, G_auxiliary_input)\n",
        "G.summary()\n",
        "\n",
        "D_in = Input(shape=(EMBEDDING_DIM,))\n",
        "D, D_out = get_discriminative(D_in)\n",
        "D.summary()\n",
        "\n",
        "GAN_input_tensor = Input([224, 224, 3])\n",
        "GAN_main_input = Input([MAX_SENT_LENGTH])\n",
        "GAN_auxiliary_input = Input([metas.shape[1]])\n",
        "GAN, GAN_out = make_gan(GAN_input_tensor, GAN_main_input, GAN_auxiliary_input, G, D)\n",
        "GAN.summary()\n",
        "\n",
        "dataset = [x_img_train, x_train, x_meta_train]\n",
        "pretrain(G, D, x_img_train, x_train, x_meta_train)\n",
        "d_loss, g_loss = train(GAN, G, D, dataset, y_train, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULixCrQwqfiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix, auc, roc_curve, precision_recall_curve\n",
        "yhat_probs, _ = G.predict([x_img_val, x_val, x_meta_val])\n",
        "yhat_classes = np.argmax(yhat_probs, axis=1)\n",
        "yhat_probs = yhat_probs[:,1]\n",
        "y_classes = np.argmax(y_val, axis=1)\n",
        "accuracy = accuracy_score(y_classes, yhat_classes)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "precision = precision_score(y_classes, yhat_classes)\n",
        "print('Precision: %f' % precision)\n",
        "recall = recall_score(y_classes, yhat_classes)\n",
        "print('Recall: %f' % recall)\n",
        "f1 = f1_score(y_classes, yhat_classes)\n",
        "print('F1 score: %f' % f1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}